{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda2/lib/python2.7/site-packages/sklearn/lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/home/max/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/max/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "#\n",
    "# Example to classify faces.\n",
    "# Brandon Amos\n",
    "# 2015/10/11\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "import argparse\n",
    "#import cv2\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import pandas as pd\n",
    "\n",
    "#import openface\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split,  KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#fileDir = os.path.dirname(os.path.realpath(__file__))\n",
    "#modelDir = os.path.join(fileDir, '..', 'models')\n",
    "#dlibModelDir = os.path.join(modelDir, 'dlib')\n",
    "#openfaceModelDir = os.path.join(modelDir, 'openface')\n",
    "\n",
    "\n",
    "def train(classfier, data, labelsNum, nClasses,):\n",
    "    labels = data[:,0]\n",
    "    embeddings = data[:,1:]\n",
    "    labelsNum = labels.tolist()\n",
    "    print(\"Training for {} classes.\".format(nClasses))\n",
    "    if classifier == 'LinearSvm':\n",
    "        clf = SVC(C=1, kernel='linear', probability=True)\n",
    "    elif classifier == 'GridSearchSvm':\n",
    "#         print(\"\"\"\n",
    "#         Warning: In our experiences, using a grid search over SVM hyper-parameters only\n",
    "#         gives marginally better performance than a linear SVM with C=1 and\n",
    "#         is not worth the extra computations of performing a grid search.\n",
    "#         \"\"\")\n",
    "        param_grid = [\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'kernel': ['linear']},\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'gamma': [0.001, 0.0001],\n",
    "             'kernel': ['rbf']}\n",
    "        ]\n",
    "        clf = GridSearchCV(SVC(C=1, probability=True), param_grid, cv=5)\n",
    "    # ref:\n",
    "    # http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#example-classification-plot-classifier-comparison-py\n",
    "    elif classifier == 'DecisionTree':  # Doesn't work best\n",
    "        clf = DecisionTreeClassifier(max_depth=20)\n",
    "    elif classifier == 'KNN':\n",
    "        clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    elif classifier == 'AdaBoost':\n",
    "        clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=100)\n",
    "    elif classifier == 'RandomForest':\n",
    "        clf = RandomForestClassifier(n_estimators=10)\n",
    "    \n",
    "    start = time.time()\n",
    "    clf.fit(embeddings, labelsNum)\n",
    "    \n",
    "    \"\"\"\n",
    "    ### saving model to local file\n",
    "    fName = \"{}/classifier.pkl\".format(workDir)\n",
    "    print(\"Saving classifier to '{}'\".format(fName))\n",
    "    with open(fName, 'w') as f:\n",
    "        pickle.dump((le, clf), f)\n",
    "    \"\"\"\n",
    "    \n",
    "    return clf, (time.time() - start)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def infer(clf, X, Y, multiple=False, verbose=True):\n",
    "    \"\"\"\n",
    "    classifierModel = \"{}/classifier.pkl\".format(workDir)\n",
    "    with open(classifierModel, 'rb') as f:\n",
    "        if sys.version_info[0] < 3:\n",
    "                (le, clf) = pickle.load(f)\n",
    "        else:\n",
    "                (le, clf) = pickle.load(f, encoding='latin1')\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO Store testing represenations in folder \n",
    "    start = time.time()\n",
    "    f_x = clf.predict(X)\n",
    "    error = np.sum(Y[:,0] != f_x) / float(len(Y))\n",
    "\n",
    "    print \"\\tTesting error is {}\".format(error)\n",
    "    return error,( time.time()-start)\n",
    "    # reps = getRep(img, multiple)\n",
    "    # if len(reps) > 1:\n",
    "    #     print(\"List of faces in image from left to right\")\n",
    "    # for r in reps:\n",
    "    #     rep = r[1].reshape(1, -1)\n",
    "    #     bbx = r[0]\n",
    "\n",
    "    #     start = time.time()\n",
    "    #     predictions = clf.predict_proba(rep).ravel()\n",
    "    #     maxI = np.argmax(predictions)\n",
    "    #     person = le.inverse_transform(maxI)\n",
    "    #     confidence = predictions[maxI]\n",
    "\n",
    "    #     if verbose:\n",
    "    #         print(\"Prediction took {} seconds.\".format(time.time() - start))\n",
    "    #     if multiple:\n",
    "    #         print(\"Predict {} @ x={} with {:.2f} confidence.\".format(person.decode('utf-8'), bbx,\n",
    "    #                                                                  confidence))\n",
    "    #     else:\n",
    "    #         print(\"Predict {} with {:.2f} confidence.\".format(person.decode('utf-8'), confidence))\n",
    "\n",
    "    #     # match prediction with label\n",
    "    #     # Sum up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings.\n",
      "(997, 128)\n",
      "(997, 1) (997, 128)\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchSvm\n",
      "[80,20] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Cross Validation results:\n",
      "\tParameters: {'kernel': 'linear', 'C': 1} with validation score of 0.949\n",
      "\tParameters: {'kernel': 'linear', 'C': 10} with validation score of 0.927\n",
      "\tParameters: {'kernel': 'linear', 'C': 100} with validation score of 0.927\n",
      "\tParameters: {'kernel': 'linear', 'C': 1000} with validation score of 0.927\n",
      "\tParameters: {'kernel': 'rbf', 'C': 1, 'gamma': 0.001} with validation score of 0.127\n",
      "\tParameters: {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001} with validation score of 0.127\n",
      "\tParameters: {'kernel': 'rbf', 'C': 10, 'gamma': 0.001} with validation score of 0.127\n",
      "\tParameters: {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001} with validation score of 0.127\n",
      "\tParameters: {'kernel': 'rbf', 'C': 100, 'gamma': 0.001} with validation score of 0.827\n",
      "\tParameters: {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001} with validation score of 0.127\n",
      "\tParameters: {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001} with validation score of 0.942\n",
      "\tParameters: {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001} with validation score of 0.828\n",
      "\t********************\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ac05568105bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclf_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mclf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mprint_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Took {} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ac05568105bc>\u001b[0m in \u001b[0;36mprint_params\u001b[0;34m(clf)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\tParameters: {} with validation score of {}\"\u001b[0m            \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_validation_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\t********************\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\tBest validation score with params {} and validation score of {}\"\u001b[0m        \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params'"
     ]
    }
   ],
   "source": [
    "workDir = \"./training-embeddings\"\n",
    "print(\"Loading embeddings.\")\n",
    "fname = \"{}/labels.csv\".format(workDir)\n",
    "labels = pd.read_csv(fname, header=None).as_matrix()[:, 0:1]\n",
    "fname = \"{}/reps.csv\".format(workDir)\n",
    "embeddings = pd.read_csv(fname, header=None).as_matrix()\n",
    "le = LabelEncoder().fit(labels)\n",
    "labelsNum = le.transform(labels)\n",
    "nClasses = len(le.classes_)\n",
    "\n",
    "print embeddings.shape\n",
    "print labels.shape, embeddings.shape\n",
    "data = np.append(labels,embeddings,axis=1)\n",
    "Y = data[:,0:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "# Split dataset\n",
    "# Train on generated embeddings\n",
    "splits = [.20,.40,.50,.60,.80]  # percentage of test set\n",
    "clf_list = ['GridSearchSvm','LinearSvm', 'DecisionTree', 'AdaBoost', 'KNN', 'RandomForest']\n",
    "\n",
    "def print_params (clf):\n",
    "    print \"Cross Validation results:\"\n",
    "    for (params, avg_validation_score, cv_scores) in clf.grid_scores_:\n",
    "        print \"\\tParameters: {} with validation score of {}\"\\\n",
    "            .format(params,round(avg_validation_score,3))\n",
    "    print \"\\t********************\"\n",
    "    print \"\\tBest validation score with params {} and validation score of {}\"\\\n",
    "        .format(clf.best_params_,round(clf.best_score_,2))\n",
    "\n",
    "for split in splits:\n",
    "    for clf_name in ['GridSearchSvm']:\n",
    "        print \"----------------------------------------------------\"\n",
    "        print \"Using classifier {}\".format(clf_name)\n",
    "        print \"[{},{}] [Train,Test] Split\".format(int(100-(split*100)),\\\n",
    "                                                int((split*100)))\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,\n",
    "                                      test_size=split,random_state=42)\n",
    "        classifier = clf_name\n",
    "        data = np.append(Y_train, X_train, axis=1)\n",
    "        clf, train_time = train(classifier, data, labelsNum, nClasses)\n",
    "        \n",
    "        if clf_name is clf_list[0]:\n",
    "            print_params(clf)\n",
    "        \n",
    "        print \"Took {} seconds\".format(train_time)\n",
    "        test_error, infer_time = infer(clf, X_test, Y_test)\n",
    "        print \"Took {} seconds\".format(infer_time)\n",
    "        \n",
    "        print \"----------------------------------------------------\"\n",
    "        print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
