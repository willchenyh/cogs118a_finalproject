{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "#\n",
    "# Example to classify faces.\n",
    "# Brandon Amos\n",
    "# 2015/10/11\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "import argparse\n",
    "#import cv2\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import pandas as pd\n",
    "\n",
    "#import openface\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split,  KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#fileDir = os.path.dirname(os.path.realpath(__file__))\n",
    "#modelDir = os.path.join(fileDir, '..', 'models')\n",
    "#dlibModelDir = os.path.join(modelDir, 'dlib')\n",
    "#openfaceModelDir = os.path.join(modelDir, 'openface')\n",
    "\n",
    "\n",
    "def train(classfier, data, labelsNum, nClasses,):\n",
    "    labels = data[:,0]\n",
    "    embeddings = data[:,1:]\n",
    "    labelsNum = labels.tolist()\n",
    "    print(\"Training for {} classes.\".format(nClasses))\n",
    "    if classifier == 'LinearSvm':\n",
    "        clf = SVC(C=1, kernel='linear', probability=True)\n",
    "    elif classifier == 'GridSearchSvm':\n",
    "#         print(\"\"\"\n",
    "#         Warning: In our experiences, using a grid search over SVM hyper-parameters only\n",
    "#         gives marginally better performance than a linear SVM with C=1 and\n",
    "#         is not worth the extra computations of performing a grid search.\n",
    "#         \"\"\")\n",
    "        param_grid = [\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'kernel': ['linear']},\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'gamma': [0.001, 0.0001],\n",
    "             'kernel': ['rbf']}\n",
    "        ]\n",
    "        clf = GridSearchCV(SVC(C=1, probability=True), param_grid, cv=5)\n",
    "    # ref:\n",
    "    # http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#example-classification-plot-classifier-comparison-py\n",
    "    elif classifier == 'DecisionTree':  # Doesn't work best\n",
    "        clf = DecisionTreeClassifier(max_depth=20)\n",
    "    elif classifier == 'GridSearchDT':\n",
    "        param_grid = [\n",
    "            {\"max_depth\": [20, 40, 60, 80, 100]}\n",
    "        ]\n",
    "        clf = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
    "    elif classifier == 'KNN':\n",
    "        clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    elif classifier == 'GridSearchKNN':\n",
    "        param_grid = [\n",
    "            {'n_neighbors': [1, 3, 5, 7, 9]}\n",
    "        ]\n",
    "        clf = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
    "    elif classifier == 'AdaBoost':\n",
    "        clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=100)\n",
    "    elif classifier == 'GridSearchAB':\n",
    "        param_grid = [\n",
    "            {'n_estimators': [20, 60, 100]}\n",
    "        ]\n",
    "        clf = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier(max_depth=60)), param_grid, cv=5)\n",
    "    elif classifier == 'RandomForest':\n",
    "        clf = RandomForestClassifier(n_estimators=10)\n",
    "    elif classifier == 'GridSearchRF':\n",
    "        param_grid = [\n",
    "            {'n_estimators': [20, 60, 100]}\n",
    "        ]\n",
    "        clf = GridSearchCV(RandomForestClassifier(max_depth=40), param_grid, cv=5)\n",
    "        \n",
    "    start = time.time()\n",
    "    clf.fit(embeddings, labelsNum)\n",
    "    return clf, (time.time() - start)\n",
    "\n",
    "\n",
    "def infer(clf, X, Y, multiple=False, verbose=True):\n",
    "    # TODO Store testing represenations in folder \n",
    "    start = time.time()\n",
    "    f_x = clf.predict(X)\n",
    "    error = np.sum(Y[:,0] != f_x) / float(len(Y))\n",
    "\n",
    "    print \"\\tTesting error is {}\".format(error)\n",
    "    return error,( time.time()-start)\n",
    "\n",
    "\n",
    "def print_params (clf):\n",
    "    print \"Cross Validation results:\"\n",
    "    for (params, avg_validation_score, cv_scores) in clf.grid_scores_:\n",
    "        print \"\\tParameters: {} with validation score of {}\"\\\n",
    "            .format(params, round(avg_validation_score,3))\n",
    "    print \"\\t********************\"\n",
    "    print \"\\tBest validation score with params {} and validation score of {}\"\\\n",
    "        .format(clf.best_params_, round(clf.best_score_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings.\n",
      "(997L, 128L)\n",
      "(997L, 1L) (997L, 128L)\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchRF\n",
      "[80,20] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 14.4179999828 seconds\n",
      "\tTesting error is 0.035\n",
      "Cross Validation results:\n",
      "\tParameters: {'n_estimators': 20} with validation score of 0.877\n",
      "\tParameters: {'n_estimators': 60} with validation score of 0.922\n",
      "\tParameters: {'n_estimators': 100} with validation score of 0.923\n",
      "\t********************\n",
      "\tBest validation score with params {'n_estimators': 100} and validation score of 0.92\n",
      "Took 0.0829999446869 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchRF\n",
      "[60,40] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 11.8800001144 seconds\n",
      "\tTesting error is 0.0902255639098\n",
      "Cross Validation results:\n",
      "\tParameters: {'n_estimators': 20} with validation score of 0.868\n",
      "\tParameters: {'n_estimators': 60} with validation score of 0.905\n",
      "\tParameters: {'n_estimators': 100} with validation score of 0.93\n",
      "\t********************\n",
      "\tBest validation score with params {'n_estimators': 100} and validation score of 0.93\n",
      "Took 0.0820000171661 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchRF\n",
      "[50,50] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 8.77499985695 seconds\n",
      "\tTesting error is 0.10621242485\n",
      "Cross Validation results:\n",
      "\tParameters: {'n_estimators': 20} with validation score of 0.849\n",
      "\tParameters: {'n_estimators': 60} with validation score of 0.896\n",
      "\tParameters: {'n_estimators': 100} with validation score of 0.924\n",
      "\t********************\n",
      "\tBest validation score with params {'n_estimators': 100} and validation score of 0.92\n",
      "Took 0.0859999656677 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchRF\n",
      "[40,60] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 7.60500001907 seconds\n",
      "\tTesting error is 0.103505843072\n",
      "Cross Validation results:\n",
      "\tParameters: {'n_estimators': 20} with validation score of 0.842\n",
      "\tParameters: {'n_estimators': 60} with validation score of 0.884\n",
      "\tParameters: {'n_estimators': 100} with validation score of 0.892\n",
      "\t********************\n",
      "\tBest validation score with params {'n_estimators': 100} and validation score of 0.89\n",
      "Took 0.095999956131 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchRF\n",
      "[20,80] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 5.24000000954 seconds\n",
      "\tTesting error is 0.295739348371\n",
      "Cross Validation results:\n",
      "\tParameters: {'n_estimators': 20} with validation score of 0.709\n",
      "\tParameters: {'n_estimators': 60} with validation score of 0.809\n",
      "\tParameters: {'n_estimators': 100} with validation score of 0.814\n",
      "\t********************\n",
      "\tBest validation score with params {'n_estimators': 100} and validation score of 0.81\n",
      "Took 0.0989999771118 seconds\n",
      "----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workDir = \"./training-embeddings\"\n",
    "print(\"Loading embeddings.\")\n",
    "fname = \"{}/labels.csv\".format(workDir)\n",
    "labels = pd.read_csv(fname, header=None).as_matrix()[:, 0:1]\n",
    "fname = \"{}/reps.csv\".format(workDir)\n",
    "embeddings = pd.read_csv(fname, header=None).as_matrix()\n",
    "le = LabelEncoder().fit(labels)\n",
    "labelsNum = le.transform(labels)\n",
    "nClasses = len(le.classes_)\n",
    "\n",
    "print embeddings.shape\n",
    "print labels.shape, embeddings.shape\n",
    "data = np.append(labels,embeddings,axis=1)\n",
    "Y = data[:,0:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "# Split dataset\n",
    "# Train on generated embeddings\n",
    "splits = [.20,.40,.50,.60,.80]  # percentage of test set\n",
    "gridsearch_list = ['GridSearchSvm', 'GridSearchDT', 'GridSearchKNN', 'GridSearchAB', 'GridSearchRF']\n",
    "clf_list = ['LinearSvm', 'DecisionTree', 'KNN', 'AdaBoost', 'RandomForest']\n",
    "\n",
    "clf_name = gridsearch_list[-1]\n",
    "for split in splits:\n",
    "    print \"----------------------------------------------------\"\n",
    "    print \"Using classifier {}\".format(clf_name)\n",
    "    print \"[{},{}] [Train,Test] Split\".format(int(100-(split*100)),\\\n",
    "                                            int((split*100)))\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y,\n",
    "                                  test_size=split,random_state=42)\n",
    "    classifier = clf_name\n",
    "    data = np.append(Y_train, X_train, axis=1)\n",
    "    clf, train_time = train(classifier, data, labelsNum, nClasses)\n",
    "    print \"Took {} seconds\".format(train_time)\n",
    "    test_error, infer_time = infer(clf, X_test, Y_test)\n",
    "    print_params(clf)\n",
    "    print \"Took {} seconds\".format(infer_time)\n",
    "\n",
    "    print \"----------------------------------------------------\"\n",
    "    print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
