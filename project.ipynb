{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "#\n",
    "# Example to classify faces.\n",
    "# Brandon Amos\n",
    "# 2015/10/11\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "import argparse\n",
    "#import cv2\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import pandas as pd\n",
    "\n",
    "#import openface\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split,  KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#fileDir = os.path.dirname(os.path.realpath(__file__))\n",
    "#modelDir = os.path.join(fileDir, '..', 'models')\n",
    "#dlibModelDir = os.path.join(modelDir, 'dlib')\n",
    "#openfaceModelDir = os.path.join(modelDir, 'openface')\n",
    "\n",
    "\n",
    "def train(classfier, data, labelsNum, nClasses,):\n",
    "    labels = data[:,0]\n",
    "    embeddings = data[:,1:]\n",
    "    labelsNum = labels.tolist()\n",
    "    print(\"Training for {} classes.\".format(nClasses))\n",
    "    if classifier == 'LinearSvm':\n",
    "        clf = SVC(C=1, kernel='linear', probability=True)\n",
    "    elif classifier == 'GridSearchSvm':\n",
    "#         print(\"\"\"\n",
    "#         Warning: In our experiences, using a grid search over SVM hyper-parameters only\n",
    "#         gives marginally better performance than a linear SVM with C=1 and\n",
    "#         is not worth the extra computations of performing a grid search.\n",
    "#         \"\"\")\n",
    "        param_grid = [\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'kernel': ['linear']},\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'gamma': [0.001, 0.0001],\n",
    "             'kernel': ['rbf']}\n",
    "        ]\n",
    "        clf = GridSearchCV(SVC(C=1, probability=True), param_grid, cv=5)\n",
    "    # ref:\n",
    "    # http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#example-classification-plot-classifier-comparison-py\n",
    "    elif classifier == 'DecisionTree':  # Doesn't work best\n",
    "        clf = DecisionTreeClassifier(max_depth=20)\n",
    "    elif classifier == 'GridSearchDT':\n",
    "        param_grid = [\n",
    "            {\"max_depth\": [5, 10, 20, 50]}\n",
    "        ]\n",
    "        clf = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
    "    elif classifier == 'KNN':\n",
    "        clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    elif classifier == 'AdaBoost':\n",
    "        clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=100)\n",
    "    elif classifier == 'RandomForest':\n",
    "        clf = RandomForestClassifier(n_estimators=10)\n",
    "    \n",
    "    start = time.time()\n",
    "    clf.fit(embeddings, labelsNum)\n",
    "    \n",
    "    \"\"\"\n",
    "    ### saving model to local file\n",
    "    fName = \"{}/classifier.pkl\".format(workDir)\n",
    "    print(\"Saving classifier to '{}'\".format(fName))\n",
    "    with open(fName, 'w') as f:\n",
    "        pickle.dump((le, clf), f)\n",
    "    \"\"\"\n",
    "    \n",
    "    return clf, (time.time() - start)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def infer(clf, X, Y, multiple=False, verbose=True):\n",
    "    \"\"\"\n",
    "    classifierModel = \"{}/classifier.pkl\".format(workDir)\n",
    "    with open(classifierModel, 'rb') as f:\n",
    "        if sys.version_info[0] < 3:\n",
    "                (le, clf) = pickle.load(f)\n",
    "        else:\n",
    "                (le, clf) = pickle.load(f, encoding='latin1')\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO Store testing represenations in folder \n",
    "    start = time.time()\n",
    "    f_x = clf.predict(X)\n",
    "    error = np.sum(Y[:,0] != f_x) / float(len(Y))\n",
    "\n",
    "    print \"\\tTesting error is {}\".format(error)\n",
    "    return error,( time.time()-start)\n",
    "    # reps = getRep(img, multiple)\n",
    "    # if len(reps) > 1:\n",
    "    #     print(\"List of faces in image from left to right\")\n",
    "    # for r in reps:\n",
    "    #     rep = r[1].reshape(1, -1)\n",
    "    #     bbx = r[0]\n",
    "\n",
    "    #     start = time.time()\n",
    "    #     predictions = clf.predict_proba(rep).ravel()\n",
    "    #     maxI = np.argmax(predictions)\n",
    "    #     person = le.inverse_transform(maxI)\n",
    "    #     confidence = predictions[maxI]\n",
    "\n",
    "    #     if verbose:\n",
    "    #         print(\"Prediction took {} seconds.\".format(time.time() - start))\n",
    "    #     if multiple:\n",
    "    #         print(\"Predict {} @ x={} with {:.2f} confidence.\".format(person.decode('utf-8'), bbx,\n",
    "    #                                                                  confidence))\n",
    "    #     else:\n",
    "    #         print(\"Predict {} with {:.2f} confidence.\".format(person.decode('utf-8'), confidence))\n",
    "\n",
    "    #     # match prediction with label\n",
    "    #     # Sum up \n",
    "\n",
    "def print_params (clf):\n",
    "    print \"Cross Validation results:\"\n",
    "    for (params, avg_validation_score, cv_scores) in clf.grid_scores_:\n",
    "        print \"\\tParameters: {} with validation score of {}\"\\\n",
    "            .format(params,round(avg_validation_score,3))\n",
    "    print \"\\t********************\"\n",
    "    print \"\\tBest validation score with params {} and validation score of {}\"\\\n",
    "        .format(clf.best_params_,round(clf.best_score_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings.\n",
      "(997L, 128L)\n",
      "(997L, 1L) (997L, 128L)\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchDT\n",
      "[80,20] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 3.79600000381 seconds\n",
      "\tTesting error is 0.43\n",
      "Took 0.010999917984 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchDT\n",
      "[60,40] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 3.40699982643 seconds\n",
      "\tTesting error is 0.466165413534\n",
      "Took 0.00499987602234 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchDT\n",
      "[50,50] [Train,Test] Split\n",
      "Training for 50 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willc\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2.66700005531 seconds\n",
      "\tTesting error is 0.496993987976\n",
      "Took 0.00500011444092 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchDT\n",
      "[40,60] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 2.13800001144 seconds\n",
      "\tTesting error is 0.537562604341\n",
      "Took 0.00499987602234 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier GridSearchDT\n",
      "[20,80] [Train,Test] Split\n",
      "Training for 50 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willc\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:552: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1.1890001297 seconds\n",
      "\tTesting error is 0.645363408521\n",
      "Took 0.00699996948242 seconds\n",
      "----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workDir = \"./training-embeddings\"\n",
    "print(\"Loading embeddings.\")\n",
    "fname = \"{}/labels.csv\".format(workDir)\n",
    "labels = pd.read_csv(fname, header=None).as_matrix()[:, 0:1]\n",
    "fname = \"{}/reps.csv\".format(workDir)\n",
    "embeddings = pd.read_csv(fname, header=None).as_matrix()\n",
    "le = LabelEncoder().fit(labels)\n",
    "labelsNum = le.transform(labels)\n",
    "nClasses = len(le.classes_)\n",
    "\n",
    "print embeddings.shape\n",
    "print labels.shape, embeddings.shape\n",
    "data = np.append(labels,embeddings,axis=1)\n",
    "Y = data[:,0:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "# Split dataset\n",
    "# Train on generated embeddings\n",
    "splits = [.20,.40,.50,.60,.80]  # percentage of test set\n",
    "gridsearch_list = ['GridSearchSvm', 'GridSearchDT']\n",
    "clf_list = ['LinearSvm', 'DecisionTree', 'AdaBoost', 'KNN', 'RandomForest']\n",
    "\n",
    "clf_name = gridsearch_list[1]\n",
    "for split in splits:\n",
    "    print \"----------------------------------------------------\"\n",
    "    print \"Using classifier {}\".format(clf_name)\n",
    "    print \"[{},{}] [Train,Test] Split\".format(int(100-(split*100)),\\\n",
    "                                            int((split*100)))\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y,\n",
    "                                  test_size=split,random_state=42)\n",
    "    classifier = clf_name\n",
    "    data = np.append(Y_train, X_train, axis=1)\n",
    "    clf, train_time = train(classifier, data, labelsNum, nClasses)\n",
    "    print \"Took {} seconds\".format(train_time)\n",
    "    test_error, infer_time = infer(clf, X_test, Y_test)\n",
    "    print_params(clf)\n",
    "    print \"Took {} seconds\".format(infer_time)\n",
    "\n",
    "    print \"----------------------------------------------------\"\n",
    "    print\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
