{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "#\n",
    "# Example to classify faces.\n",
    "# Brandon Amos\n",
    "# 2015/10/11\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "import argparse\n",
    "#import cv2\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import pandas as pd\n",
    "\n",
    "#import openface\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split,  KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#fileDir = os.path.dirname(os.path.realpath(__file__))\n",
    "#modelDir = os.path.join(fileDir, '..', 'models')\n",
    "#dlibModelDir = os.path.join(modelDir, 'dlib')\n",
    "#openfaceModelDir = os.path.join(modelDir, 'openface')\n",
    "\n",
    "\n",
    "def train(classfier, data, labelsNum, nClasses,):\n",
    "    labels = data[:,0]\n",
    "    embeddings = data[:,1:]\n",
    "    labelsNum = labels.tolist()\n",
    "    print(\"Training for {} classes.\".format(nClasses))\n",
    "    if classifier == 'LinearSvm':\n",
    "        clf = SVC(C=1, kernel='linear', probability=True)\n",
    "    elif classifier == 'GridSearchSvm':\n",
    "        print(\"\"\"\n",
    "        Warning: In our experiences, using a grid search over SVM hyper-parameters only\n",
    "        gives marginally better performance than a linear SVM with C=1 and\n",
    "        is not worth the extra computations of performing a grid search.\n",
    "        \"\"\")\n",
    "        param_grid = [\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'kernel': ['linear']},\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'gamma': [0.001, 0.0001],\n",
    "             'kernel': ['rbf']}\n",
    "        ]\n",
    "        clf = GridSearchCV(SVC(C=1, probability=True), param_grid, cv=5)\n",
    "    # ref:\n",
    "    # http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#example-classification-plot-classifier-comparison-py\n",
    "    elif classifier == 'DecisionTree':  # Doesn't work best\n",
    "        clf = DecisionTreeClassifier(max_depth=20)\n",
    "    elif classifier == 'KNN':\n",
    "        clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    elif classifier == 'AdaBoost':\n",
    "        clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=100)\n",
    "    elif classifier == 'RandomForest':\n",
    "        clf = RandomForestClassifier(n_estimators=10)\n",
    "    \n",
    "    start = time.time()\n",
    "    clf.fit(embeddings, labelsNum)\n",
    "    \n",
    "    \"\"\"\n",
    "    ### saving model to local file\n",
    "    fName = \"{}/classifier.pkl\".format(workDir)\n",
    "    print(\"Saving classifier to '{}'\".format(fName))\n",
    "    with open(fName, 'w') as f:\n",
    "        pickle.dump((le, clf), f)\n",
    "    \"\"\"\n",
    "    \n",
    "    return clf, (time.time() - start)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def infer(clf, X, Y, multiple=False, verbose=True):\n",
    "    \"\"\"\n",
    "    classifierModel = \"{}/classifier.pkl\".format(workDir)\n",
    "    with open(classifierModel, 'rb') as f:\n",
    "        if sys.version_info[0] < 3:\n",
    "                (le, clf) = pickle.load(f)\n",
    "        else:\n",
    "                (le, clf) = pickle.load(f, encoding='latin1')\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO Store testing represenations in folder \n",
    "    start = time.time()\n",
    "    f_x = clf.predict(X)\n",
    "    error = np.sum(Y[:,0] != f_x) / float(len(Y))\n",
    "\n",
    "    print \"\\tTesting error is {}\".format(error)\n",
    "    return error,( time.time()-start)\n",
    "    # reps = getRep(img, multiple)\n",
    "    # if len(reps) > 1:\n",
    "    #     print(\"List of faces in image from left to right\")\n",
    "    # for r in reps:\n",
    "    #     rep = r[1].reshape(1, -1)\n",
    "    #     bbx = r[0]\n",
    "\n",
    "    #     start = time.time()\n",
    "    #     predictions = clf.predict_proba(rep).ravel()\n",
    "    #     maxI = np.argmax(predictions)\n",
    "    #     person = le.inverse_transform(maxI)\n",
    "    #     confidence = predictions[maxI]\n",
    "\n",
    "    #     if verbose:\n",
    "    #         print(\"Prediction took {} seconds.\".format(time.time() - start))\n",
    "    #     if multiple:\n",
    "    #         print(\"Predict {} @ x={} with {:.2f} confidence.\".format(person.decode('utf-8'), bbx,\n",
    "    #                                                                  confidence))\n",
    "    #     else:\n",
    "    #         print(\"Predict {} with {:.2f} confidence.\".format(person.decode('utf-8'), confidence))\n",
    "\n",
    "    #     # match prediction with label\n",
    "    #     # Sum up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings.\n",
      "(997, 128)\n",
      "(997, 1) (997, 128)\n",
      "----------------------------------------------------\n",
      "Using classifier LinearSvm\n",
      "[80,20] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.743131160736 seconds\n",
      "\tTesting error is 0.015\n",
      "Took 0.0352008342743 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier DecisionTree\n",
      "[80,20] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.276422023773 seconds\n",
      "\tTesting error is 0.47\n",
      "Took 0.00220799446106 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier AdaBoost\n",
      "[80,20] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 35.9209120274 seconds\n",
      "\tTesting error is 0.15\n",
      "Took 0.0456609725952 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier KNN\n",
      "[80,20] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.00850820541382 seconds\n",
      "\tTesting error is 0.045\n",
      "Took 0.0397350788116 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier RandomForest\n",
      "[80,20] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.193612098694 seconds\n",
      "\tTesting error is 0.175\n",
      "Took 0.0124161243439 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier LinearSvm\n",
      "[60,40] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.545794963837 seconds\n",
      "\tTesting error is 0.0451127819549\n",
      "Took 0.061224937439 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier DecisionTree\n",
      "[60,40] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.261914968491 seconds\n",
      "\tTesting error is 0.568922305764\n",
      "Took 0.0101311206818 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier AdaBoost\n",
      "[60,40] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 28.8589987755 seconds\n",
      "\tTesting error is 0.187969924812\n",
      "Took 0.0746600627899 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier KNN\n",
      "[60,40] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.00730013847351 seconds\n",
      "\tTesting error is 0.0576441102757\n",
      "Took 0.0643651485443 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier RandomForest\n",
      "[60,40] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.164256095886 seconds\n",
      "\tTesting error is 0.240601503759\n",
      "Took 0.0130889415741 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier LinearSvm\n",
      "[50,50] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.455323934555 seconds\n",
      "\tTesting error is 0.0721442885772\n",
      "Took 0.0592911243439 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier DecisionTree\n",
      "[50,50] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.181777000427 seconds\n",
      "\tTesting error is 0.573146292585\n",
      "Took 0.00506401062012 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier AdaBoost\n",
      "[50,50] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 22.7877590656 seconds\n",
      "\tTesting error is 0.25250501002\n",
      "Took 0.180590867996 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier KNN\n",
      "[50,50] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.0079550743103 seconds\n",
      "\tTesting error is 0.0521042084168\n",
      "Took 0.114025831223 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier RandomForest\n",
      "[50,50] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.222057104111 seconds\n",
      "\tTesting error is 0.256513026052\n",
      "Took 0.0272080898285 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier LinearSvm\n",
      "[40,60] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.3662981987 seconds\n",
      "\tTesting error is 0.108514190317\n",
      "Took 0.0619189739227 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier DecisionTree\n",
      "[40,60] [Train,Test] Split\n",
      "Training for 50 classes.\n",
      "Took 0.144582986832 seconds\n",
      "\tTesting error is 0.621035058431\n",
      "Took 0.00929689407349 seconds\n",
      "----------------------------------------------------\n",
      "\n",
      "----------------------------------------------------\n",
      "Using classifier AdaBoost\n",
      "[40,60] [Train,Test] Split\n",
      "Training for 50 classes.\n"
     ]
    }
   ],
   "source": [
    "workDir = \"./training-embeddings\"\n",
    "print(\"Loading embeddings.\")\n",
    "fname = \"{}/labels.csv\".format(workDir)\n",
    "labels = pd.read_csv(fname, header=None).as_matrix()[:, 0:1]\n",
    "fname = \"{}/reps.csv\".format(workDir)\n",
    "embeddings = pd.read_csv(fname, header=None).as_matrix()\n",
    "le = LabelEncoder().fit(labels)\n",
    "labelsNum = le.transform(labels)\n",
    "nClasses = len(le.classes_)\n",
    "\n",
    "print embeddings.shape\n",
    "print labels.shape, embeddings.shape\n",
    "data = np.append(labels,embeddings,axis=1)\n",
    "Y = data[:,0:1]\n",
    "X = data[:,1:]\n",
    "\n",
    "# Split dataset\n",
    "# Train on generated embeddings\n",
    "splits = [.20,.40,.50,.60,.80]  # percentage of test set\n",
    "clf_list = ['GridSearchSVM','LinearSvm', 'DecisionTree', 'AdaBoost', 'KNN', 'RandomForest']\n",
    "\n",
    "for split in splits:\n",
    "    for clf_name in clf_list:\n",
    "        print \"----------------------------------------------------\"\n",
    "        print \"Using classifier {}\".format(clf_name)\n",
    "        print \"[{},{}] [Train,Test] Split\".format(int(100-(split*100)),\\\n",
    "                                                int((split*100)))\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,\n",
    "                                      test_size=split,random_state=42)\n",
    "        classifier = clf_name\n",
    "        data = np.append(Y_train, X_train, axis=1)\n",
    "        clf, train_time = train(classifier, data, labelsNum, nClasses)\n",
    "        print \"Took {} seconds\".format(train_time)\n",
    "        test_error, infer_time = infer(clf, X_test, Y_test)\n",
    "        print \"Took {} seconds\".format(infer_time)\n",
    "        \n",
    "        print \"----------------------------------------------------\"\n",
    "        print\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
