{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings.\n",
      "(997L, 128L)\n",
      "(997L, 1L) (997L, 128L)\n",
      "----------------------------------------------------\n",
      "[80,20] [Train,Test] Split\n",
      "Loading embeddings.\n",
      "Training for 50 classes.\n",
      "\tTesting error is 0.045\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "[60,40] [Train,Test] Split\n",
      "Loading embeddings.\n",
      "Training for 50 classes.\n",
      "\tTesting error is 0.0576441102757\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "[50,50] [Train,Test] Split\n",
      "Loading embeddings.\n",
      "Training for 50 classes.\n",
      "\tTesting error is 0.0521042084168\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "[40,60] [Train,Test] Split\n",
      "Loading embeddings.\n",
      "Training for 50 classes.\n",
      "\tTesting error is 0.0550918196995\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "[20,80] [Train,Test] Split\n",
      "Loading embeddings.\n",
      "Training for 50 classes.\n",
      "\tTesting error is 0.135338345865\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "#\n",
    "# Example to classify faces.\n",
    "# Brandon Amos\n",
    "# 2015/10/11\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "import argparse\n",
    "#import cv2\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import pandas as pd\n",
    "\n",
    "#import openface\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split,  KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#fileDir = os.path.dirname(os.path.realpath(__file__))\n",
    "#modelDir = os.path.join(fileDir, '..', 'models')\n",
    "#dlibModelDir = os.path.join(modelDir, 'dlib')\n",
    "#openfaceModelDir = os.path.join(modelDir, 'openface')\n",
    "\n",
    "\n",
    "def train(classfier, data, labelsNum, nClasses,):\n",
    "    print(\"Loading embeddings.\")\n",
    "    fname = \"{}/labels.csv\".format(workDir)\n",
    "    labels = data[:,0]\n",
    "    embeddings = data[:,1:]\n",
    "    labelsNum = labels.tolist()\n",
    "    print(\"Training for {} classes.\".format(nClasses))\n",
    "    if classifier == 'LinearSvm':\n",
    "        clf = SVC(C=1, kernel='linear', probability=True)\n",
    "    elif classifier == 'GridSearchSvm':\n",
    "        print(\"\"\"\n",
    "        Warning: In our experiences, using a grid search over SVM hyper-parameters only\n",
    "        gives marginally better performance than a linear SVM with C=1 and\n",
    "        is not worth the extra computations of performing a grid search.\n",
    "        \"\"\")\n",
    "        param_grid = [\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'kernel': ['linear']},\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'gamma': [0.001, 0.0001],\n",
    "             'kernel': ['rbf']}\n",
    "        ]\n",
    "        clf = GridSearchCV(SVC(C=1, probability=True), param_grid, cv=5)\n",
    "    # ref:\n",
    "    # http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#example-classification-plot-classifier-comparison-py\n",
    "    elif classifier == 'DecisionTree':  # Doesn't work best\n",
    "        clf = DecisionTreeClassifier(max_depth=20)\n",
    "    elif classifier == 'KNN':\n",
    "        clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    elif classifier == 'AdaBoost':\n",
    "        clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=100)\n",
    "    elif classifier == 'RandomForest':\n",
    "        clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "    clf.fit(embeddings, labelsNum)\n",
    "\n",
    "    \"\"\"\n",
    "    ### saving model to local file\n",
    "    fName = \"{}/classifier.pkl\".format(workDir)\n",
    "    print(\"Saving classifier to '{}'\".format(fName))\n",
    "    with open(fName, 'w') as f:\n",
    "        pickle.dump((le, clf), f)\n",
    "    \"\"\"\n",
    "    \n",
    "    return clf\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def infer(clf, X, Y, multiple=False, verbose=True):\n",
    "    \"\"\"\n",
    "    classifierModel = \"{}/classifier.pkl\".format(workDir)\n",
    "    with open(classifierModel, 'rb') as f:\n",
    "        if sys.version_info[0] < 3:\n",
    "                (le, clf) = pickle.load(f)\n",
    "        else:\n",
    "                (le, clf) = pickle.load(f, encoding='latin1')\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO Store testing represenations in folder \n",
    "    f_x = clf.predict(X)\n",
    "    error = np.sum(Y[:,0] != f_x) / float(len(Y))\n",
    "\n",
    "    print \"\\tTesting error is {}\".format(error)\n",
    "    return error\n",
    "    # reps = getRep(img, multiple)\n",
    "    # if len(reps) > 1:\n",
    "    #     print(\"List of faces in image from left to right\")\n",
    "    # for r in reps:\n",
    "    #     rep = r[1].reshape(1, -1)\n",
    "    #     bbx = r[0]\n",
    "\n",
    "    #     start = time.time()\n",
    "    #     predictions = clf.predict_proba(rep).ravel()\n",
    "    #     maxI = np.argmax(predictions)\n",
    "    #     person = le.inverse_transform(maxI)\n",
    "    #     confidence = predictions[maxI]\n",
    "\n",
    "    #     if verbose:\n",
    "    #         print(\"Prediction took {} seconds.\".format(time.time() - start))\n",
    "    #     if multiple:\n",
    "    #         print(\"Predict {} @ x={} with {:.2f} confidence.\".format(person.decode('utf-8'), bbx,\n",
    "    #                                                                  confidence))\n",
    "    #     else:\n",
    "    #         print(\"Predict {} with {:.2f} confidence.\".format(person.decode('utf-8'), confidence))\n",
    "\n",
    "    #     # match prediction with label\n",
    "    #     # Sum up \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    workDir = \"./training-embeddings\"\n",
    "    print(\"Loading embeddings.\")\n",
    "    fname = \"{}/labels.csv\".format(workDir)\n",
    "    labels = pd.read_csv(fname, header=None).as_matrix()[:, 0:1]\n",
    "    fname = \"{}/reps.csv\".format(workDir)\n",
    "    embeddings = pd.read_csv(fname, header=None).as_matrix()\n",
    "    le = LabelEncoder().fit(labels)\n",
    "    labelsNum = le.transform(labels)\n",
    "    nClasses = len(le.classes_)\n",
    "\n",
    "    print embeddings.shape\n",
    "    print labels.shape, embeddings.shape\n",
    "    data = np.append(labels,embeddings,axis=1)\n",
    "    Y = data[:,0:1]\n",
    "    X = data[:,1:]\n",
    "\n",
    "    # Split dataset\n",
    "    # Train on generated embeddings\n",
    "    splits = [.20,.40,.50,.60,.80]  # percentage of test set\n",
    "    clf_list = ['LinearSvm', 'DecisionTree', 'AdaBoost', 'KNN', 'RandomForest']\n",
    "    for split in splits:\n",
    "        print \"----------------------------------------------------\"\n",
    "        print \"[{},{}] [Train,Test] Split\".format(int(100-(split*100)),\\\n",
    "                                                int((split*100)))\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,Y,\n",
    "                                      test_size=split,random_state=42)\n",
    "        classifier = clf_list[3]\n",
    "        data = np.append(Y_train, X_train, axis=1)\n",
    "        clf = train(classifier, data, labelsNum, nClasses)\n",
    "\n",
    "        test_error = infer(clf, X_test, Y_test)\n",
    "        print \"----------------------------------------------------\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
